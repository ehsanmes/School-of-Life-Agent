import os
import feedparser
import telegram
import asyncio
import time
import random
from bs4 import BeautifulSoup
from openai import OpenAI
from datetime import datetime, timedelta

# --- 1. CONFIGURATION ---
AVALAI_API_KEY = os.environ.get("AVALAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
AVALAI_BASE_URL = "https://api.avalai.ir/v1"
MODEL_TO_USE = "gpt-4o-mini" 

# --- FINAL, VERIFIED RSS FEEDS ---
JOURNAL_FEEDS = {
    "The School of Life": "https://www.theschooloflife.com/feed/",
    "Aeon": "https://aeon.co/feed.rss",
    "The Marginalian": "https://www.themarginalian.org/feed/",
    "Nautilus": "https://nautil.us/feed/",
    "Big Think": "https://bigthink.com/feed/",
    "Scientific American Mind & Brain": "http://rss.sciam.com/sciam/mind-and-brain",
    "Quanta Magazine": "https://api.quantamagazine.org/feed/",
    "The Atlantic - Ideas": "https://www.theatlantic.com/feed/channel/ideas/"
}
DAYS_TO_CHECK = 30 # ÙÙ‚Ø· Ù…Ù‚Ø§Ù„Ø§Øª Û²Û´ Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡
MEMORY_FILE = "_posted_articles.txt" # ÙØ§ÛŒÙ„ Ø­Ø§ÙØ¸Ù‡

# --- 2. INITIALIZE THE AI CLIENT ---
client = None
if AVALAI_API_KEY:
    try:
        client = OpenAI(api_key=AVALAI_API_KEY, base_url=AVALAI_BASE_URL)
        print("âœ… AvalAI client configured successfully.")
    except Exception as e:
        print(f"âŒ Critical error during client initialization: {e}")
else:
    print("âŒ AVALAI_API_KEY secret is not set.")

# --- 3. FUNCTIONS ---

def get_posted_links():
    """Ù„ÛŒØ³Øª Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø³Øª Ø´Ø¯Ù‡ Ø±Ø§ Ø§Ø² Ø­Ø§ÙØ¸Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯"""
    try:
        with open(MEMORY_FILE, 'r') as f:
            return set(line.strip() for line in f.readlines() if line.strip())
    except FileNotFoundError:
        print("Memory file not found. Will create one.")
        return set()

def add_link_to_memory(link):
    """Ù„ÛŒÙ†Ú© Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¨Ù‡ ÙØ§ÛŒÙ„ Ø­Ø§ÙØ¸Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    try:
        with open(MEMORY_FILE, 'a') as f:
            f.write(link + '\n')
        print(f"Updated memory file with new link: {link}")
    except Exception as e:
        print(f"Error writing to memory file: {e}")

def get_unposted_article(feeds, posted_links):
    """Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…Ù‚Ø§Ù„Ø§ØªÛŒ Ú©Ù‡ Ù¾Ø³Øª Ù†Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ Ø±Ø§ Ø§Ø² Ù‡Ù…Ù‡ ÙÛŒØ¯Ù‡Ø§ Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯"""
    print("Fetching articles from all live feeds...")
    cutoff_date = datetime.now() - timedelta(days=DAYS_TO_CHECK)
    new_articles_found = []
    
    for journal, url in feeds.items():
        print(f"Checking feed: {journal}")
        try:
            feed = feedparser.parse(url)
            if not feed.entries:
                print(f"No entries found for {journal}.")
                continue
                
            for entry in feed.entries:
                link = entry.link
                if link in posted_links:
                    continue # Ø§ÛŒÙ† Ù…Ù‚Ø§Ù„Ù‡ Ù‚Ø¨Ù„Ø§Ù‹ Ù¾Ø³Øª Ø´Ø¯Ù‡ Ø§Ø³Øª

                published_time_struct = getattr(entry, 'published_parsed', None)
                if published_time_struct:
                     published_time = datetime(*published_time_struct[:6])
                     if published_time >= cutoff_date:
                        print(f"Found new article: {entry.title}")
                        
                        content_html = entry.get('content', [{}])[0].get('value', '')
                        if not content_html:
                            content_html = getattr(entry, 'description', '')
                        
                        summary_text = BeautifulSoup(content_html, 'html.parser').get_text()
                        
                        article = {
                            "title": entry.title.strip(),
                            "link": link,
                            "content": summary_text,
                            "source": journal # Ù†Ø§Ù… Ù…Ù†Ø¨Ø¹
                        }
                        new_articles_found.append(article)
                        break 
        except Exception as e: 
            print(f"Could not fetch or parse feed for {journal}. Error: {e}")
    
    if not new_articles_found:
        print("No new (unposted) articles found in any feed.")
        return None
        
    chosen_article = random.choice(new_articles_found)
    return chosen_article

def summarize_and_format(article):
    """Ù…Ù‚Ø§Ù„Ù‡ Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØªØŒ Ø®Ù„Ø§ØµÙ‡ Ú©Ø±Ø¯Ù‡ØŒ Ù‡Ø´ØªÚ¯ Ù…ÛŒâ€ŒØ³Ø§Ø²Ø¯ Ùˆ Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    if client is None: return "AI client is not available.", None
    print(f"Analyzing article: {article['title']}")
    
    # --- STEP 1: Generate Summary ---
    system_message_summary = "Ø´Ù…Ø§ ÛŒÚ© Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡ Ùˆ Ù…ØªÙÚ©Ø± Ø¹Ù…ÛŒÙ‚ Ù…Ø³Ù„Ø· Ø¨Ù‡ ÙÙ„Ø³ÙÙ‡ Ùˆ Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ Ù‡Ø³ØªÛŒØ¯. ÙˆØ¸ÛŒÙÙ‡ Ø´Ù…Ø§ Ø¯Ø±ÛŒØ§ÙØª ÛŒÚ© Ù…Ù‚Ø§Ù„Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ùˆ Ù†ÙˆØ´ØªÙ† ÛŒÚ© Ø®Ù„Ø§ØµÙ‡ ØªØ­Ù„ÛŒÙ„ÛŒ Ø¹Ù…ÛŒÙ‚ Ùˆ Ù…ÙÙ‡ÙˆÙ…ÛŒ (Ø­Ø¯ÙˆØ¯ Û²ÛµÛ° ØªØ§ Û³Û°Û° Ú©Ù„Ù…Ù‡) Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª. Ø®Ù„Ø§ØµÙ‡ Ø¨Ø§ÛŒØ¯ Ø±ÙˆØ§Ù†ØŒ Ø¬Ø°Ø§Ø¨ Ùˆ ÙÙ„Ø³ÙÛŒ Ø¨Ø§Ø´Ø¯. Ù…ÙØ§Ù‡ÛŒÙ… Ø§ØµÙ„ÛŒ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ù…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ (Ù…Ø§Ù†Ù†Ø¯ ğŸ’¡, ğŸ¯, ğŸ§ ) Ø¨Ù‡ Ø¬Ø§ÛŒ Ø¨ÙˆÙ„Øª Ù¾ÙˆÛŒÙ†ØªØŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù†ÛŒØ¯ ØªØ§ Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ Ø¨Ø§Ù„Ø§ Ø¨Ø±ÙˆØ¯. Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø®Ù„Ø§ØµÙ‡ Ø±Ø§ Ø´Ø±ÙˆØ¹ Ú©Ù†ÛŒØ¯ Ùˆ Ù‡ÛŒÚ† Ù…Ù‚Ø¯Ù…Ù‡ ÛŒØ§ ØªÙˆØ¶ÛŒØ­ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ú©Ø§Ø±ÛŒ Ú©Ù‡ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯ Ù†Ù†ÙˆÛŒØ³ÛŒØ¯."
    user_message_summary = f"Please summarize this article in a detailed, 250-300 word, fluid, and engaging Persian summary, using emojis for key concepts:\n\nTitle: {article['title']}\n\nContent:\n{article['content']}"
    
    persian_summary = ""
    try:
        completion_summary = client.chat.completions.create(model=MODEL_TO_USE, messages=[{"role": "system", "content": system_message_summary}, {"role": "user", "content": user_message_summary}], max_tokens=3000, temperature=0.7)
        persian_summary = completion_summary.choices[0].message.content.strip()
        print("âœ… Summary generated successfully.")
    except Exception as e:
        print(f"Could not analyze article. Error: {e}")
        return None, None

    # --- STEP 2: Translate Title ---
    print("Waiting for 5 seconds...")
    time.sleep(5)
    system_message_title = "Translate the following English title to Persian. Only return the translated text, nothing else."
    user_message_title = article['title']
    persian_title = article['title'] 
    try:
        completion_title = client.chat.completions.create(model=MODEL_TO_USE, messages=[{"role": "system", "content": system_message_title}, {"role": "user", "content": user_message_title}], max_tokens=100, temperature=0.1)
        persian_title = completion_title.choices[0].message.content.strip()
        print(f"âœ… Title translated successfully: {persian_title}")
    except Exception as e:
        print(f"Could not translate title. Error: {e}")

    # --- STEP 3: Generate Hashtags ---
    print("Waiting for 5 seconds...")
    time.sleep(5)
    system_message_hashtags = "You are a metadata specialist. Read the following text and generate exactly 5 relevant, single-word hashtags in Persian. Do not include the '#' symbol. Separate them with commas."
    user_message_hashtags = f"Text:\n{persian_summary}"
    hashtags_string = ""
    try:
        completion_tags = client.chat.completions.create(model=MODEL_TO_USE, messages=[{"role": "system", "content": system_message_hashtags}, {"role": "user", "content": user_message_hashtags}], max_tokens=100, temperature=0.2)
        tags = completion_tags.choices[0].message.content.strip()
        hashtags_string = " ".join([f"#{tag.strip().replace(' ', '_')}" for tag in tags.split(',')]) 
        print(f"âœ… Hashtags generated: {hashtags_string}")
    except Exception as e:
        print(f"Could not generate hashtags. Error: {e}")
        hashtags_string = f"#{article['source'].lower().replace(' ', '')}" 

    # --- STEP 4: Assemble Final Post ---
    final_post = (
        f"<b>{persian_title}</b>\n\n" 
        f"{persian_summary}\n\n"
        f"{hashtags_string}\n\n"
        f"<i>Ù…Ù†Ø¨Ø¹: {article['source']}</i>\n"
        f"<a href='{article['link']}'>Ø§Ø¯Ø§Ù…Ù‡ Ù…Ø·Ù„Ø¨</a>\n"
        f"@momento_lab ğŸ’¡"
    )
    return final_post, article['link']
        
async def send_to_telegram(report, token, chat_id):
    if not token or not chat_id: print("Telegram secrets not found."); return
    print("Sending post to Telegram...")
    try:
        bot = telegram.Bot(token=token)
        await bot.send_message(
            chat_id=chat_id, 
            text=report, 
            parse_mode='HTML',
            disable_web_page_preview=False
        )
        print("Post successfully sent.")
    except Exception as e: print(f"Failed to send post. Error: {e}")

# --- 5. EXECUTION (with memory logic) ---
def main():
    if client is None:
        print("Agent will not run. Check API Key.")
        return

    posted_links = get_posted_links()
    new_article = get_unposted_article(JOURNAL_FEEDS, posted_links)
    
    if new_article is None:
        print("No new (unposted) articles found in any feed. Stopping.")
        print("\n--- AGENT RUN FINISHED ---")
        return
        
    print(f"New article selected! Processing: {new_article['title']}")
    report, new_link = summarize_and_format(new_article)
    
    if report:
        asyncio.run(send_to_telegram(report, TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID))
        add_link_to_memory(new_link) 
    else:
        print("Failed to generate report.")
        
    print("\n--- AGENT RUN FINISHED ---")

if __name__ == "__main__":
    main()
